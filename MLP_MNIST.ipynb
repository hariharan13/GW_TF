{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of MLP using mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check shape \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create validation dataset\n",
    "x_val=\n",
    "y_val=\n",
    "x_train=\n",
    "y_train="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape the data\n",
    "x_train=x_train.reshape()\n",
    "x_test=x_test.reshape()\n",
    "x_val=x_val.reshape()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert y labels to one hot encoding\n",
    "num_classes=\n",
    "y_train=tf.keras.utils.to_categorical(y_train,num_classes)\n",
    "y_val=tf.keras.utils.to_categorical(y_val,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the data\n",
    "x_train=x_train.astype(\"float32\")\n",
    "x_test=x_test.astype(\"float32\")\n",
    "x_val=x_val.astype(\"float32\")\n",
    "\n",
    "gray_value=\n",
    "x_train/=gray_value\n",
    "x_test/=gray_value\n",
    "x_val/=gray_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model building \n",
    "#create placeholder\n",
    "X=tf.placeholder(tf.float32,[None,])\n",
    "Y=tf.placeholder(tf.float32,[None,])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model with layer one-256 neuron,layer two with 128 neuron\n",
    "def mlp(X):\n",
    "    w1=tf.Variable(tf.random_uniform([]))\n",
    "    b1=tf.Variable(tf.zeros([]))\n",
    "    h1=tf.nn.relu(tf.matmul(X,w1)+b1)\n",
    "    w2=tf.Variable(tf.random_uniform([]))\n",
    "    b2=tf.Variable(tf.zeros([]))\n",
    "    h2=tf.nn.relu(tf.matmul(h1,w2)+b2)\n",
    "    out_layer=tf.Variable(tf.random_uniform([]))\n",
    "    b3=tf.Variable(tf.zeros([]))\n",
    "    logits=tf.matmul(h2,out_layer)+b3\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits=mlp(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_op=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=Y))(#softmax_with_cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op=tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "epoch_cnt=30\n",
    "batch_size=\n",
    "iteration=len(x_train)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epoch_cnt):\n",
    "        start=0\n",
    "        end=batch_size\n",
    "        avg_loss=0\n",
    "        for i in range(iteration):\n",
    "            _,loss=sess.run([train_op,loss_op],feed_dict={X:x_train[start:end],Y:y_train[start:end]})\n",
    "            epoch_cnt+=1\n",
    "            start+=batch_size\n",
    "            end+=batch_size\n",
    "            avg_loss+=loss/iteration\n",
    "        #validate\n",
    "        pred=tf.nn.softmax(logits)\n",
    "        correct=tf.equal(tf.argmax(pred,1),tf.argmax(Y,1))\n",
    "        accuracy=tf.reduce_mean(tf.cast(correct,'float'))\n",
    "        current_acc=accuracy.eval({X:x_train,Y:y_train})\n",
    "        print(\"Epoch:\"  + str(epoch) + \"validation acc: \" + str(current_acc) + \"loss:\" +str(avg_loss))\n",
    "    #test\n",
    "    pred=tf.nn.softmax(logits)\n",
    "    correct=tf.equal(tf.argmax(pred,1),tf.argmax(Y,1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct,'float'))\n",
    "    print(\"Final_test_acc: \",accuracy.eval({X:x_train,Y:y_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
